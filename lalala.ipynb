{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export KEY_MYSQL='1533542415'\n",
    "export API_KEY_YELP=\"Ln6gcw24qn2x3RFJn0D89tGTBCRfrrpRrXqEp7y8fsaDFd2yjf7byiYcDirTF0VNr-bgsPE_kZPRqY0mpv7pXVd5KuVpzQC8cX5NzywiwBH1djTKvzQqNumm83JkZXYx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Index(['id', 'url', 'text', 'rating', 'time_created', 'user.id',\n",
      "       'user.profile_url', 'user.image_url', 'user.name', 'business_id'],\n",
      "      dtype='object') columnas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from mysql_connection import *\n",
    "from transform_API import *\n",
    "import pymysql as mysql\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_ER():\n",
    "    \n",
    "    \"\"\"\n",
    "        Esta funcion realiza el proceso de ETL completo respecto de la API de yelp para los restaurantes en la base datos mysql.\n",
    "        Para esto aplica las funciones:\n",
    "            * extract_businesses\n",
    "            * transform_business\n",
    "            * get_table\n",
    "            * mysql_get_connection\n",
    "            * get_categories\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    yelp_new_data = pd.read_parquet('./datalake/business_trasnform.parquet') # Realizo las trasnformaciones necesarias para que los datos esten limpios\n",
    "\n",
    "    yelp_origen = get_table('business_yelp') # Cargo de la base de datos la tabla de yelp en un dataframe\n",
    "    \n",
    "    yelp_new_data = yelp_new_data[~(yelp_new_data['business_id'].isin(yelp_origen['business_id']))] #De los restaurantes extraidos tomo solo los que su id NO esta en la DB\n",
    "    print(f'La cantidad de restaurantes a ingestar es {yelp_new_data.shape[0]}')\n",
    "    if yelp_new_data.shape[0] != 0:\n",
    "        conexion = get_connection_mysql() # Genero una conexion a mysql\n",
    "        cursor = conexion.cursor() \n",
    "        \n",
    "        consulta = \"INSERT INTO business_yelp  VALUES(%s,%s,%s,%s,%s,%s)\" \n",
    "        yelp_insert = yelp_new_data[['business_id','name','latitude','longitude','stars','state_id']].copy()\n",
    "        cursor.executemany(consulta,yelp_insert.values.tolist() ) # Inserto los nuevos locales, sin insertar las categorias\n",
    "        print(f'{yelp_insert.shape[0]} nuevos negocios')\n",
    "        conexion.commit()\n",
    "        conexion.close()\n",
    "        \n",
    "        categories_origen = get_table('categories') # Cargo la tabla de categorias de la base de datos.    \n",
    "        max_id = categories_origen['categories_id'].max()\n",
    "        categorias_new_data = get_categories(yelp_new_data.copy())\n",
    "\n",
    "        #Agrego la categoria Restaurants a cada local\n",
    "        \n",
    "        df_restaurant = categorias_new_data.drop_duplicates(subset='business_id').copy()\n",
    "        df_restaurants = categorias_new_data.drop_duplicates(subset='business_id').copy()\n",
    "        \n",
    "        df_restaurant['categories'] = 'restaurants'\n",
    "        df_restaurants['categories'] = 'restaurants'\n",
    "        categorias_new_data = pd.concat([categorias_new_data,df_restaurant])\n",
    "        categorias_new_data = pd.concat([categorias_new_data,df_restaurants])\n",
    "\n",
    "        \n",
    "        \n",
    "        categorias_new = categorias_new_data[~(categorias_new_data['categories'].isin(categories_origen['name']))] # Selecciono las categorias que no estan en la DB\n",
    "        categorias_new.loc[:, 'categories_id'] = range(max_id + 1, max_id + 1 + categorias_new.shape[0])\n",
    "\n",
    "\n",
    "        categories = categorias_new.drop_duplicates(subset='categories').copy() # Elimino las categorias duplicadas y las convierto en lista de listas.\n",
    "        conexion = get_connection_mysql() \n",
    "        cursor = conexion.cursor()\n",
    "        \n",
    "        # Ingesto las nuevas categorias.\n",
    "        consulta = \"INSERT INTO categories  VALUES(%s,%s)\"\n",
    "        cursor.executemany(consulta, categories[['categories_id','categories']].values.tolist())\n",
    "        print(f'{categories.shape[0]} nuevas categorias ingestadas')\n",
    "        conexion.commit()\n",
    "        conexion.close()\n",
    "        \n",
    "        \n",
    "        categories_acualizada = get_table('categories') # Cargo la tabla de categorias actualizada.\n",
    "        \n",
    "        #Hago un join entre la tabla business_id,categoria creada anteriormente con las categorias de la BD, y me quedo solo con business_id y categoria id\n",
    "        categorias_yelp_new =  pd.merge(categories_acualizada,categorias_new_data,left_on='name',right_on='categories',how='inner')\n",
    "        \n",
    "        conexion = get_connection_mysql()\n",
    "        \n",
    "        categorias_yelp_new['categories_id'] = categorias_yelp_new['categories_id'].astype(int)\n",
    "        \n",
    "        \n",
    "        # Como business id ya es unico simplemente agrego las filas a la tabla cateogires_yelp\n",
    "        try:\n",
    "            cursor = conexion.cursor()\n",
    "            consulta = \"INSERT INTO categories_yelp  VALUES(%s,%s)\"\n",
    "            cursor.executemany(consulta, categorias_yelp_new[['business_id','categories_id']].values.tolist())\n",
    "            conexion.commit()\n",
    "            conexion.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar la consulta SQL: {e}\")\n",
    "            # Aquí puedes agregar código adicional para manejar la excepción según tus necesidades.\n",
    "            # Por ejemplo, podrías hacer un rollback si es necesario.\n",
    "        finally:\n",
    "            # Este bloque se ejecutará siempre, asegurando que la conexión se cierre incluso en caso de excepción.\n",
    "            if conexion and conexion.open:\n",
    "                conexion.rollback()  # Hacer un rollback en caso de excepción antes de cerrar la conexión.\n",
    "                conexion.close()\n",
    "    else:\n",
    "        return 'No habian restaurantes para ingestar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de restaurantes a ingestar es 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No habian restaurantes para ingestar'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_ER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funciones auxiliares como get_connection_mysql, get_review_yelp, etc.\n",
    "\n",
    "def yelp_review_ER():\n",
    "    \"\"\"\n",
    "    Esta función realiza el proceso de ETL completo respecto de la API de Yelp para las reviews de restaurantes y las sube en la base de datos MySQL.\n",
    "    Para esto aplica las funciones:\n",
    "        * extract_businesses\n",
    "        * transform_business\n",
    "        * get_table\n",
    "        * mysql_get_connection\n",
    "    \"\"\"\n",
    "    # Leer datos de reviews desde el archivo parquet\n",
    "    \n",
    "    # Obtener las reviews existentes en la base de datos\n",
    "    \n",
    "    review_new_data = pd.read_parquet('./datalake/reviews_yelp_transform.parquet') # Hago las trasnformaciones sobre el dataframe.\n",
    "    \n",
    "    reviews_yelp_origen = get_review_yelp('reviews_yelp') # Consulto la tabla las ultimas resenas\n",
    "\n",
    "    users_old = get_filtered_table('user_yelp', review_new_data['user_id'].unique().tolist())\n",
    "    \n",
    "\n",
    "\n",
    "    print(users_old.shape[0])\n",
    "    #Filtro solo las reviews donde su columna date sea mayor a la maxima existente en la base de datos.\n",
    "    print(f'{review_new_data.shape[0]} reviews a ingestar')\n",
    "    \n",
    "    review_new_data = pd.merge(review_new_data, reviews_yelp_origen[['review_id']], on='review_id', how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "    \n",
    "    #review_new_data = review_new_data[(~review_new_data['review_id'].isin(reviews_yelp_origen['review_id']))]\n",
    "    review_new_data['date'] = pd.to_datetime(review_new_data['date'])\n",
    "\n",
    "\n",
    "    \n",
    "    #### USERS ####  \n",
    "\n",
    "    grouped_data = review_new_data.groupby('user_id') # Rrealizo el agrupamiento por usuarios y calculas las metricas.\n",
    "    min_dates = grouped_data['date'].min()\n",
    "    first_names = grouped_data['name'].first()\n",
    "    review_counts = grouped_data['review_id'].count()\n",
    "    mean_stars = grouped_data['stars'].mean()\n",
    "    users = pd.DataFrame({\n",
    "        'name': first_names,\n",
    "        'creation': min_dates,\n",
    "        'review_count': review_counts,\n",
    "        'stars': mean_stars\n",
    "    }).reset_index()\n",
    "    users['influence'] = 0\n",
    "    users = users[['user_id','name','creation','review_count','influence','stars']]\n",
    "    #### DATAFRAME CON LOS USUARIOS NUEVOS\n",
    "    new_users = users[~(users['user_id'].isin(users_old['user_id']))]\n",
    "    new_users['influence'] = 0\n",
    "    \n",
    "    \n",
    "     #### DATAFRAME CON LOS USUARIOS EXISTENTES\n",
    "    #exist_user = users[(users['user_id'].isin(users_old['user_id']))] # Usuarios existentes\n",
    "    \n",
    "    \n",
    "    exist_user = pd.concat([users_old, users[users['user_id'].isin(users_old['user_id'])]]) # Hago un merge de los usuarios de la BD y la llegada\n",
    "    # Para los nuevos usuarios encuentro la nueva review_count y stars\n",
    "    exist_user['stars'] = exist_user['stars'].astype('float')\n",
    "    # Realizo el agrupamiento por usuarios existentes y calculo las metricas.\n",
    "    grouped_data = exist_user.groupby('user_id')\n",
    "    min_dates = grouped_data['creation'].min()\n",
    "    first_names = grouped_data['name'].first()\n",
    "    review_counts = grouped_data['review_count'].count()\n",
    "    mean_stars = grouped_data['stars'].mean()\n",
    "    exist_user = pd.DataFrame({\n",
    "        'name': first_names,\n",
    "        'creation': min_dates,\n",
    "        'review_count': review_counts,\n",
    "        'stars': mean_stars\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(exist_user)\n",
    "    \n",
    "    if not exist_user.empty:\n",
    "        try:\n",
    "            conexion = get_connection_mysql()\n",
    "            cursor = conexion.cursor()\n",
    "            \n",
    "            consulta_new_user = (\n",
    "            'INSERT INTO user_yelp  VALUES(%s,%s,%s,%s,%s,%s)'\n",
    "                )\n",
    "\n",
    "            # Ejecutar la consulta con execumany.\n",
    "            cursor.executemany(consulta_new_user, new_users[['user_id', 'name','creation', 'review_count', 'influence','stars']].values.tolist())\n",
    "            print(f'{new_users.shape[0]} usuarios nuevos cargados.')\n",
    "            # Consulta de actualización con placeholders.\n",
    "            consulta_old_user = (\n",
    "                \"UPDATE user_yelp \"\n",
    "                \"SET name = %s, creation = %s, review_count = %s, stars = %s \"\n",
    "                \"WHERE user_id = %s\"\n",
    "            )\n",
    "\n",
    "            # Ejecutar la consulta con execumany.\n",
    "            cursor.executemany(consulta_old_user, exist_user[['name', 'creation', 'review_count', 'stars', 'user_id']].values.tolist())\n",
    "            print(f'{exist_user.shape[0]} usuarios actualizados.')\n",
    "            conexion.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar la consulta SQL: {e}\")\n",
    "            # Maneja la excepción según tus necesidades.\n",
    "            # Puedes hacer un rollback si es necesario.\n",
    "        finally:\n",
    "            # Cierra la conexión en el bloque finally para asegurar que se cierre incluso en caso de excepción.\n",
    "            if conexion and conexion.open:\n",
    "                conexion.rollback()\n",
    "                conexion.close()\n",
    "            \n",
    "    print(review_new_data.shape[0]) \n",
    "    \n",
    "    # Verificación de review_id antes de la inserción\n",
    "    conexion = get_connection_mysql()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    review_id_list = review_new_data['review_id'].tolist()\n",
    "\n",
    "    # Crear una cadena con los review_id para la consulta SQL\n",
    "    review_id_str = ','.join([f\"'{review_id}'\" for review_id in review_id_list])\n",
    "\n",
    "    # Consulta SQL para verificar si los review_id existen en la tabla\n",
    "    consulta_existencia = f\"SELECT review_id FROM reviews_yelp WHERE review_id IN ({review_id_str})\"\n",
    "    cursor.execute(consulta_existencia)\n",
    "\n",
    "    # Obtener los review_id que existen en la base de datos\n",
    "    review_id_existente = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    # Filtrar la lista original de review_id para obtener aquellos que no existen en la base de datos\n",
    "    review_id_no_existente = [review_id for review_id in review_id_list if review_id not in review_id_existente]\n",
    "\n",
    "    conexion.close()\n",
    "\n",
    "    # Filtrar el DataFrame para mantener solo los registros con review_id que no existen en la base de datos\n",
    "    review_new_data_filtered = review_new_data[review_new_data['review_id'].isin(review_id_no_existente)]\n",
    "\n",
    "    # Inserción de registros en la tabla reviews_yelp para los review_id que no existen\n",
    "    try:\n",
    "        conexion = get_connection_mysql()\n",
    "        cursor = conexion.cursor()\n",
    "\n",
    "        review_new_data_filtered.drop_duplicates(subset='review_id', inplace=True)\n",
    "\n",
    "        consulta = \"INSERT INTO reviews_yelp VALUES(%s, %s, %s, %s, %s, %s)\"\n",
    "        cursor.executemany(consulta, review_new_data_filtered.drop(columns=['name']).values.tolist())\n",
    "\n",
    "        print(f'{review_new_data_filtered.shape[0]} nuevas reviews insertadas')\n",
    "\n",
    "        conexion.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al ejecutar la consulta SQL: {e}\")\n",
    "        if conexion:\n",
    "            conexion.rollback()\n",
    "    finally:\n",
    "        if conexion:\n",
    "            conexion.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33 reviews a ingestar\n",
      "                   user_id           name            creation  review_count  \\\n",
      "0   2PqLjZ0oX5l-zZbdJYJLvg            Jon 2017-02-11 01:17:07             1   \n",
      "1   7EjeGRHhDkfGCYXX4qw9Mg          Kathy 2018-07-06 15:16:46             2   \n",
      "2   BAu3Er2Bft8Y0MUWa0ZKCA          Allen 2014-11-25 17:12:22             1   \n",
      "3   Es1On-acj0BtbsQ65GDN6A       Giovanna 2018-09-10 03:46:50             1   \n",
      "4   F85s2ozxnwIrOIs7t1jTLg     Candace M. 2023-01-21 09:32:18             1   \n",
      "5   HZ_kJP3C_YAGHRL_LaSvVQ         Sandra 2018-06-10 12:44:59             1   \n",
      "6   JJHUDLhqxTvHVll-IqFb9w              L 2017-07-13 04:00:58             2   \n",
      "7   JfmoxgXfQ0Ry0p9BpUeiuw           Mark 2013-05-03 01:27:04             1   \n",
      "8   K-SJigmcAhKF-AV3vxqjlw         Teh H. 2022-11-13 21:20:17             1   \n",
      "9   MRa2O7cX1507JEOkijR8Ig          Kevin 2011-11-30 21:29:51             1   \n",
      "10  MkmvvzUCWS6tJGTw-VIgvw        Justine 2016-11-20 04:07:52             1   \n",
      "11  OCwLhS1CwFYwmzTnKpdkpg             Ed 2014-12-30 05:10:54             2   \n",
      "12  Ry1IsShkReepKGSOOTf3Ew              J 2016-04-19 16:46:59             1   \n",
      "13  TdH-18Kc9pB15MYX-T0Wcw              J 2016-04-30 15:21:11             2   \n",
      "14  UN6MXJuhyGcX7LTj4-b7FA         Warren 2006-03-12 04:04:23             2   \n",
      "15  UiGZ1r7H1e3n1VhrRVDTEw           Jess 2014-08-06 01:59:45             1   \n",
      "16  XIkX0MgnhndkqVNQGOK4ig         Lianna 2012-01-09 11:57:34             1   \n",
      "17  Y2iAub6uz6QxlaL8POb8Jw          Ciela 2016-03-22 17:46:25             1   \n",
      "18  cQ4I8nDqgu7qrqdP-7X74Q         Daniel 2014-11-25 05:09:51             2   \n",
      "19  fr1Hz2acAb3OaL3l6DyKNg           Boon 2014-05-10 17:13:19             1   \n",
      "20  gD27VTgPF_AmVPs5BLJxew          Wayne 2021-02-23 22:01:21             1   \n",
      "21  hkZOAj9cPzCAcVnrZq2JNA       Staci S. 2023-06-05 19:40:51             1   \n",
      "22  i1rfAHZv44Q_Hrk3yf-10A              M 2018-04-22 11:54:03             1   \n",
      "23  j8UODb7MWmuraUTg9RGcXQ            Lee 2012-11-24 05:13:14             2   \n",
      "24  jl_XX_0ujzIrbjUWYLMVTA            Ash 2018-01-31 05:35:46             2   \n",
      "25  k3p0YH8i_aVlYq0O-a0pLQ         Martin 2014-01-12 06:54:13             2   \n",
      "26  l6wnVM_nt73_B7Dj7PINkg      Candie G. 2023-05-09 20:05:50             1   \n",
      "27  mdwi4hkXuLrqlv8OVsG3qQ          Sarah 2021-04-11 01:52:16             1   \n",
      "28  pctgUvk8c3bDpNZKiSB9hg          Jason 2014-09-25 20:08:35             2   \n",
      "29  qhUgJ83GRhQ4yZIqApbfmg         Dnr422 2016-12-30 14:59:59             1   \n",
      "30  wWnhpP3QSbyKDR1CDoBqDA  Alexandria R. 2021-06-10 04:21:02             2   \n",
      "31  y6DlNI80TeFEE0unmmtEuQ              L 2011-04-17 18:10:42             2   \n",
      "32  zUKeZNu4tCG56xjwWH54Vw           Bill 2008-12-05 18:54:54             2   \n",
      "\n",
      "    stars  \n",
      "0   3.680  \n",
      "1   4.170  \n",
      "2   2.630  \n",
      "3   5.000  \n",
      "4   1.000  \n",
      "5   5.000  \n",
      "6   4.605  \n",
      "7   2.860  \n",
      "8   2.000  \n",
      "9   2.340  \n",
      "10  4.810  \n",
      "11  4.820  \n",
      "12  4.250  \n",
      "13  4.685  \n",
      "14  5.000  \n",
      "15  3.980  \n",
      "16  4.580  \n",
      "17  5.000  \n",
      "18  4.565  \n",
      "19  3.120  \n",
      "20  4.340  \n",
      "21  4.000  \n",
      "22  3.670  \n",
      "23  4.115  \n",
      "24  4.875  \n",
      "25  1.450  \n",
      "26  3.000  \n",
      "27  1.500  \n",
      "28  4.115  \n",
      "29  3.400  \n",
      "30  3.000  \n",
      "31  1.360  \n",
      "32  4.085  \n",
      "0 usuarios nuevos cargados.\n",
      "33 usuarios actualizados.\n",
      "13\n",
      "0 nuevas reviews insertadas\n"
     ]
    }
   ],
   "source": [
    "yelp_review_ER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
